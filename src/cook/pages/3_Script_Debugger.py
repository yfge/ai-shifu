from uuid import uuid4
import concurrent.futures

from tools.auth import login
from tools.utils import *
from tools.dev_tools import *
from models.script import *
from init import cfg

_ = load_dotenv(find_dotenv())


# ==================== å„ç§åˆå§‹åŒ–å·¥ä½œ ====================
# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(
    page_title="Script Debugger",
    page_icon="ðŸ§™â€â™‚ï¸",
    initial_sidebar_state="collapsed",
    layout="wide",
    menu_items={
        'Get Help': 'https://www.extremelycoolapp.com/help',
        'Report a bug': "https://www.extremelycoolapp.com/bug",
        'About': "# This is a header. This is an *extremely* cool app!"
    }
)

# é¡µé¢å†…çš„å¤§æ ‡é¢˜å°æ ‡é¢˜
'# å‰§æœ¬è°ƒè¯•å™¨ ðŸžðŸ“œðŸž'
st.caption('')

# éœ€è¦ç™»å½•
if login():

    # åˆå§‹åŒ–è¦è°ƒè¯•çš„æ¨¡åž‹åˆ—è¡¨
    if 'debug_models' not in st.session_state:
        st.session_state.debug_models = []

    # åˆå§‹åŒ–è¦è°ƒè¯•çš„å•æ¡å‰§æœ¬
    if 'debug_script' not in st.session_state:
        st.session_state.debug_script = None

    #
    # nickname = st.query_params.get('nickname')
    # industry = st.query_params.get('industry')
    # occupation = st.query_params.get('occupation')
    # ai_tools = st.query_params.get('ai_tools')
    # table = st.query_params.get('table')
    #
    # if progress := st.query_params.get('progress'):
    #     st.session_state.progress = int(progress) - 1
    #     st.session_state.nickname = nickname if nickname else 'å°æ˜Ž'
    #     st.session_state.industry = industry if industry else 'äº’è”ç½‘'
    #     st.session_state.occupation = occupation if occupation else 'äº§å“ç»ç†'
    #     st.session_state.ai_tools = ai_tools if ai_tools else 'GitHub_Copilot'
    #     st.session_state.table = table if table else None
    #     if st.session_state.table:
    #         load_scripts_and_system_role(cfg.LARK_APP_TOKEN, st.session_state.table, cfg.DEF_LARK_VIEW_ID)
    #         if 'system_role' in st.session_state:
    #             st.session_state.progress -= 1
    #         logging.debug(f'ä»Ž {st.session_state.progress} å¼€å§‹å‰§æœ¬ï¼ˆ{st.session_state.table}ï¼‰')
    #     else:
    #         logging.debug(f'ä»Ž {st.session_state.progress} å¼€å§‹é»˜è®¤å‰§æœ¬ï¼ˆ{cfg.DEF_LARK_TABLE_ID}ï¼‰')
    #     st.session_state.has_started = True
    #     st.rerun()


    # =========================================================
    # ===== é…ç½® ç”¨æˆ·Profile
    col1, col2, col3, col4, col5 = st.columns(5, gap='small')
    with col1:
        st.session_state.nickname = st.text_input('é»˜è®¤æ˜µç§°', value='å°æ˜Ž')
    with col2:
        st.session_state.industry = st.text_input('é»˜è®¤è¡Œä¸š', value='äº’è”ç½‘')
    with col3:
        st.session_state.occupation = st.text_input('é»˜è®¤èŒä¸š', value='äº§å“ç»ç†')
    with col4:
        st.session_state.ai_tools = st.text_input('é»˜è®¤AIå·¥å…·', value='GitHub_Copilot')
    with col5:
        st.session_state.style = st.selectbox('é»˜è®¤é£Žæ ¼', ('å¹½é»˜é£Žè¶£', 'ä¸¥è‚ƒä¸“ä¸š', 'é¼“åŠ±æ¸©æš–'))
    # with col2:
        # with st.expander('é»˜è®¤ LLM é…ç½®'):
        #     cfg.set_default_model(st.selectbox('é»˜è®¤ LLMï¼š', cfg.SUPPORT_MODELS,
        #                                        index=cfg.SUPPORT_MODELS.index(cfg.DEFAULT_MODEL)))
        #     cfg.set_qianfan_default_temperature(st.number_input('QianFan é»˜è®¤æ¸©åº¦ï¼š', value=cfg.QIANFAN_DEF_TMP))
        #     cfg.set_openai_default_temperature(st.number_input('OpenAI é»˜è®¤æ¸©åº¦ï¼š', value=cfg.OPENAI_DEF_TMP))


    # =========================================================
    # ===== åŠ è½½ æŒ‡å®šå•æ¡å‰§æœ¬
    col1, col2 = st.columns([0.7, 0.3], gap='small')
    with col1:
        chapter = st.selectbox('é€‰æ‹©å‰§æœ¬ï¼š', load_chapters_from_sqlite())
    with col2:
        progress = st.number_input('å¼€å§‹ä½ç½®ï¼š', value=2, min_value=1, step=1) - 2

    if st.button(f'åŠ è½½å‰§æœ¬', type='primary', use_container_width=True):
        # åŠ è½½å‰§æœ¬åŠç³»ç»Ÿè§’è‰²
        load_scripts_and_system_role(cfg.LARK_APP_TOKEN, chapter.lark_table_id, chapter.lark_view_id)
        progress += 1 if 'system_role' not in st.session_state else 0
        st.session_state.progress = progress
        logging.debug(f'ä»Ž {st.session_state.progress} å¼€å§‹å‰§æœ¬')
        script: Script = st.session_state.script_list[progress]
        st.session_state.debug_script = script

        with st.expander('å‰§æœ¬è¯¦æƒ…'):
            st.write(script)

        if 'system_role' in st.session_state:
            with st.expander('ç³»ç»Ÿè§’è‰²'):
                st.text_area('ç³»ç»Ÿè§’è‰²', st.session_state.system_role, height=200, label_visibility='hidden')

        if script.type == ScriptType.FIXED and script.check_template == 'æœªå¡«å†™ï¼':
            st.error('è¯¥å‰§æœ¬ä¸ºå›ºå®šå‰§æœ¬ï¼Œä¸”æ²¡æœ‰ç”¨æˆ·è¾“å…¥éœ€è¦æ£€æŸ¥ï¼Œä¸éœ€è¦æµ‹è¯•ï¼')
        else:
            edited_template = st.text_area('æ¨¡ç‰ˆå†…å®¹', script.template, height=200)
            st.write(f"æ¨¡ç‰ˆå†…å®¹å…±è®¡ {len(edited_template)} ä¸ªå­—ç¬¦")
            if script.check_template != 'æœªå¡«å†™ï¼':
                edited_check_template = st.text_area('æ£€æŸ¥æ¨¡ç‰ˆå†…å®¹', script.check_template, height=200)
                st.write(f"æ£€æŸ¥æ¨¡ç‰ˆå†…å®¹å…±è®¡ {len(edited_check_template)} ä¸ªå­—ç¬¦")



    # =========================================================
    # ===== é…ç½® è¦è°ƒè¯•çš„æ¨¡åž‹
    st.write('## æ¨¡åž‹é…ç½®')
    col1, col2 = st.columns(2, gap='medium')
    with col1:
        models = []
        model = st.selectbox('é€‰æ‹©æ¨¡åž‹ï¼š', cfg.SUPPORT_MODELS, index=cfg.SUPPORT_MODELS.index(cfg.DEFAULT_MODEL))
        temperature = 0
        if model in cfg.QIANFAN_MODELS:
            temperature = cfg.QIANFAN_DEF_TMP
        elif model in cfg.ZHIPU_MODELS:
            temperature = cfg.ZHIPU_DEF_TMP
        elif model in cfg.OPENAI_MODELS:
            temperature = cfg.OPENAI_DEF_TMP
        temperature = st.number_input('è®¾å®šæ¸©åº¦ï¼š', value=temperature)
        if st.button('æ·»åŠ æµ‹è¯•æ¨¡åž‹ -->',  use_container_width=True):
            if (model, temperature) not in st.session_state.debug_models:
                st.session_state.debug_models.append((model, temperature))
    with col2:
        df_models = st.dataframe(
            st.session_state.debug_models,
            column_config={
                1: "æ¨¡åž‹",
                2: "æ¸©åº¦",
            },
            use_container_width=True,
            hide_index=True,
            on_select="rerun",
            selection_mode=["multi-row", "multi-column"],
        )

        select_rows: list = df_models.selection['rows']
        if select_rows:
            # .write(f'é€‰ä¸­çš„è¡Œï¼š{select_rows}')
            if st.button(f'åˆ é™¤é€‰ä¸­è¡Œï¼š{select_rows}', use_container_width=True):
                select_rows.sort(reverse=True)
                for row in select_rows:
                    if row < len(st.session_state.debug_models):
                        st.session_state.debug_models.pop(row)
                    else:
                        st.error(f"æ— æ•ˆçš„è¡Œç´¢å¼•: {row}")
                st.rerun()


    # =========================================================
    # ===== å¼€å§‹æµ‹è¯•
    def debug_model(model, temperature, script, system_role):
        # ========== chat_box åˆå§‹åŒ– ==========
        chat_box = ChatBox(assistant_avatar=ICON_SIFU, session_key=str(uuid4()))
        chat_box.init_session()
        chat_box.output_messages()

        st.session_state.system_role = system_role

        if script.check_template != 'æœªå¡«å†™ï¼':
            full_result = streaming_from_template(
                chat_box, script.check_template, {'input': user_input},
                input_done_with=script.check_ok_sign,
                parse_keys=script.parse_vars,
                model=model, temperature=temperature)
        else:
            full_result = streaming_from_template(
                chat_box, script.template,
                {v: st.session_state[v] for v in script.template_vars} if script.template_vars else None,
                model=model, temperature=temperature
            )
        logging.debug(f'scrip id: {script.id}, chat result: {full_result}')
        # st.write(full_result)
        return model, temperature, full_result


    def debug_model2(model, temperature, script, variables, system_role, user_input):

        if script.check_template == 'æœªå¡«å†™ï¼':
            full_result = from_template(script.template, variables, system_role, model, temperature)
        else:
            full_result = from_template(script.check_template, {'input': user_input}, None, model, temperature)
        logging.debug(f'scrip id: {script.id}, chat result: {full_result}')
        # st.write(full_result)
        return model, temperature, full_result


    add_vertical_space(2)
    col1, col2, col3 = st.columns([0.25, 0.25, 0.5])
    with col1:
        test_times = st.number_input('åˆ—æ•°(ä¸€ä¸ªæ¨¡åž‹æµ‹å‡ é)ï¼š', value=4, min_value=1, step=1)
    with col2:
        max_height = st.number_input('æœ€å¤§è¡Œé«˜ï¼š', value=300, min_value=100, step=10)
    with col3:
        user_input = st.text_input('ç”¨æˆ·è¾“å…¥', placeholder=st.session_state.debug_script.input_placeholder)

    is_norm_prompt = True
    if st.session_state.debug_script.check_template == 'æœªå¡«å†™ï¼':
        st.write('æµ‹è¯•å†…å®¹ä¸º Promptæ¨¡ç‰ˆï¼Œ å¯æ”¹å†™')
        st.session_state.debug_script.template = st.text_area('ä¿®æ”¹æ¨¡ç‰ˆå†…å®¹', st.session_state.debug_script.template, height=200)
    else:
        st.write('æµ‹è¯•å†…å®¹ä¸º æ£€æŸ¥ç”¨æˆ·è¾“å…¥çš„æ¨¡ç‰ˆï¼Œ å¯æ”¹å†™')
        st.session_state.debug_script.check_template = st.text_area('ä¿®æ”¹æ£€æŸ¥æ¨¡ç‰ˆå†…å®¹', st.session_state.debug_script.check_template, height=200)
        is_norm_prompt = False
    if st.button('å¼€å§‹æµ‹è¯•', type='primary', use_container_width=True):
        # col_num = len(st.session_state.debug_models) if len(st.session_state.debug_models) <= max_col_num else max_col_num
        # row_num = (len(st.session_state.debug_models) + col_num - 1) // col_num
        # cols = st.columns(col_num)

        # threads = []
        # # åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹
        # for i in range(row_num):
        #     cols = st.columns(col_num)
        #     for j in range(col_num):
        #         index = i * col_num + j
        #         if index < len(st.session_state.debug_models):
        #             model, temperature = st.session_state.debug_models[index]
        #             thread = threading.Thread(
        #                 target=debug_model,
        #                 args=(model, temperature, debug_prompt, st.session_state.debug_script.check_template != 'æœªå¡«å†™ï¼', cols[j]))
        #             add_script_run_ctx(thread)
        #             # threads.append(thread)
        #             thread.start()
        #
        # # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        # for thread in threads:
        #     thread.join()

        # for i in range(row_num):
        #     cols = st.columns(col_num)
        #     for j, (model, temperature) in enumerate(st.session_state.debug_models[i * col_num: (i + 1) * col_num]):
        #         with cols[j]:
        #             st.write(f'æ¨¡åž‹ï¼š{model}ï¼Œ æ¸©åº¦ï¼š{temperature}')
        #
        #             # ========== chat_box åˆå§‹åŒ– ==========
        #             chat_box = ChatBox(assistant_avatar=ICON_SIFU, session_key=str(uuid4()))
        #             chat_box.init_session()
        #             chat_box.output_messages()
        #
        #             script = st.session_state.debug_script
        #
        #             if script.check_template == 'æœªå¡«å†™ï¼':
        #                 full_result = streaming_from_template(
        #                     chat_box, debug_prompt,
        #                     {v: st.session_state[v] for v in script.template_vars} if script.template_vars else None,
        #                     model=script.custom_model, temperature=script.temperature
        #                 )
        #             else:
        #                 # é€šè¿‡ `æ£€æŸ¥æ¨¡ç‰ˆ` è¾“å‡ºAIå›žå¤
        #                 full_result = streaming_from_template(
        #                     chat_box, debug_prompt, {'input': user_input},
        #                     input_done_with=script.check_ok_sign,
        #                     parse_keys=script.parse_vars,
        #                     model=script.custom_model, temperature=script.temperature)
        #                 logging.debug(f'scrip id: {script.id}, chat result: {full_result}')

        # åˆå§‹åŒ–çº¿ç¨‹æ± 
        executor = concurrent.futures.ThreadPoolExecutor()

        futures = []
        for model, temperature in st.session_state.debug_models:
            # æäº¤è®¡ç®—ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
            # future = executor.submit(debug_model, model, temperature, st.session_state.debug_script, st.session_state.system_role)
            for i in range(test_times):
                future = executor.submit(
                    debug_model2, model, temperature, st.session_state.debug_script,
                    {v: st.session_state[v] for v in st.session_state.debug_script.template_vars} if st.session_state.debug_script.template_vars else None,
                    st.session_state.system_role if 'system_role' in st.session_state else None,
                    user_input)
                futures.append(future)

        # æ”¶é›†è®¡ç®—ç»“æžœ
        with st.spinner('æ­£åœ¨è¾“å‡ºï¼Œè¯·ç¨åŽ...'):
            results = [future.result() for future in concurrent.futures.as_completed(futures)]

        # # è®¡ç®—åˆ—æ•°å’Œè¡Œæ•°
        # col_num = len(st.session_state.debug_models) if len(st.session_state.debug_models) <= max_col_num else max_col_num
        # row_num = (len(st.session_state.debug_models) + col_num - 1) // col_num

        # æ ¹æ®æ”¶é›†çš„ç»“æžœæ˜¾ç¤º
        for i in range(len(st.session_state.debug_models)):
            cols = st.columns(test_times)
            for j in range(test_times):
                model, temperature, result = results[i * test_times + j]
                with cols[j]:
                    st.write(f'#### {model}ï¼Œ temp={temperature}')
                    st.write(result)
            st.write('-----')
